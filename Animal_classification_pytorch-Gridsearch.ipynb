{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09bf57ed",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56206916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import cv2 \n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from keras.utils import to_categorical\n",
    "from tqdm.notebook import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.optim as optim\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36012652",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ab35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzip Data Completed\n"
     ]
    }
   ],
   "source": [
    "num_samples = 500\n",
    "folder_path = r\"anike\\animal classification\"\n",
    "data_path = os.path.join(folder_path, 'Data')\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "def unzip_data():\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file) \n",
    "            if path.endswith(\".zip\"):\n",
    "                with ZipFile(path, 'r') as zf:\n",
    "                    zf.extractall(path=data_path)\n",
    "    print(\"Unzip Data Completed\")\n",
    "\n",
    "unzip_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56947dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASG0014jz1_1.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASG001e0h4_1.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>zebras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASG0014jzl_1.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASG0014jxg_0.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASG0014iqp_0.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>ASG001e0qj_2.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>zebras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ASG001e0nk_2.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>zebras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>ASG001e0mw_0.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>zebras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>ASG0014k67_0.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ASG001dwa3_0.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>zebras</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image                                           filepath   \n",
       "0    ASG0014jz1_1.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...  \\\n",
       "1    ASG001e0h4_1.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "2    ASG0014jzl_1.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "3    ASG0014jxg_0.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "4    ASG0014iqp_0.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "..                 ...                                                ...   \n",
       "995  ASG001e0qj_2.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "996  ASG001e0nk_2.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "997  ASG001e0mw_0.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "998  ASG0014k67_0.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "999  ASG001dwa3_0.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "\n",
       "        target  \n",
       "0    elephants  \n",
       "1       zebras  \n",
       "2    elephants  \n",
       "3    elephants  \n",
       "4    elephants  \n",
       "..         ...  \n",
       "995     zebras  \n",
       "996     zebras  \n",
       "997     zebras  \n",
       "998  elephants  \n",
       "999     zebras  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def build_data():\n",
    "    data = []\n",
    "    for folder in os.listdir(data_path):\n",
    "        if folder.startswith(\"train_\"):\n",
    "            target = folder.split(\"_\")[-1]\n",
    "            folder_path = os.path.join(data_path, folder)\n",
    "            files_class = []\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(\".jpeg\") and len(files_class) < num_samples:\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    files_class.append(file_path)\n",
    "                    data.append({'image': file_name, 'filepath': file_path, 'target': target})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "data = build_data()\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93ed59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASG0014jz1_1.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>elephants</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASG001e0h4_1.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>zebras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASG0014jzl_1.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>elephants</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASG0014jxg_0.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>elephants</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASG0014iqp_0.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>elephants</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>ASG001e0qj_2.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>zebras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ASG001e0nk_2.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>zebras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>ASG001e0mw_0.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>zebras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>ASG0014k67_0.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>elephants</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ASG001dwa3_0.jpeg</td>\n",
       "      <td>C:\\Users\\anike\\animal classification\\Data\\trai...</td>\n",
       "      <td>zebras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image                                           filepath   \n",
       "0    ASG0014jz1_1.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...  \\\n",
       "1    ASG001e0h4_1.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "2    ASG0014jzl_1.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "3    ASG0014jxg_0.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "4    ASG0014iqp_0.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "..                 ...                                                ...   \n",
       "995  ASG001e0qj_2.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "996  ASG001e0nk_2.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "997  ASG001e0mw_0.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "998  ASG0014k67_0.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "999  ASG001dwa3_0.jpeg  C:\\Users\\anike\\animal classification\\Data\\trai...   \n",
       "\n",
       "        target  class  \n",
       "0    elephants      0  \n",
       "1       zebras      1  \n",
       "2    elephants      0  \n",
       "3    elephants      0  \n",
       "4    elephants      0  \n",
       "..         ...    ...  \n",
       "995     zebras      1  \n",
       "996     zebras      1  \n",
       "997     zebras      1  \n",
       "998  elephants      0  \n",
       "999     zebras      1  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert string labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['class'] = label_encoder.fit_transform(data['target'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a5f4c",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb7dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 800\n",
      "Validation dataset size: 200\n"
     ]
    }
   ],
   "source": [
    "class_samples = data.groupby('target').head(num_samples)\n",
    "train_size = int(0.8 * len(class_samples))\n",
    "train_dataset = class_samples[:train_size]\n",
    "val_dataset = class_samples[train_size:]\n",
    "\n",
    "print(\"Training dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d111f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images and CSV files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_images_folder = os.path.join(data_path, 'train_images')\n",
    "val_images_folder = os.path.join(data_path, 'val_images')\n",
    "os.makedirs(train_images_folder, exist_ok=True)\n",
    "os.makedirs(val_images_folder, exist_ok=True)\n",
    "\n",
    "# Save images into folders\n",
    "def save_images(dataset, target_folder):\n",
    "    for index, row in dataset.iterrows():\n",
    "        image_path = row['filepath']\n",
    "        target_class = row['target']\n",
    "        class_folder = os.path.join(target_folder, target_class)\n",
    "        os.makedirs(class_folder, exist_ok=True)\n",
    "        shutil.copy(image_path, class_folder)\n",
    "\n",
    "# Save training images\n",
    "save_images(train_dataset, train_images_folder)\n",
    "\n",
    "# Save validation images\n",
    "save_images(val_dataset, val_images_folder)\n",
    "\n",
    "# Save CSV files\n",
    "train_csv_path=os.path.join(data_path,'train_dataset.csv')\n",
    "val_csv_path=os.path.join(data_path,'val_dataset.csv')\n",
    "train_dataset.to_csv(train_csv_path, index=False)\n",
    "val_dataset.to_csv(val_csv_path, index=False)\n",
    "\n",
    "print(\"Images and CSV files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f22edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 1])\n",
    "#         print(img_name)\n",
    "        image = Image.open(img_name)\n",
    "        label = self.data_frame.iloc[idx, 3]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7fa63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomDataset(csv_file=train_csv_path, root_dir=train_images_folder, transform=transform)\n",
    "val_dataset = CustomDataset(csv_file=val_csv_path, root_dir=val_images_folder, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c79c186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes=len(np.unique(data['target']))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0307da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, num_classes, conv1_kernel_size=5,dropout=0.3):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=conv1_kernel_size, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=conv1_kernel_size, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 128)  \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  \n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x)) \n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 16 * 56 * 56)\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc1(x)) \n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55faac39",
   "metadata": {},
   "source": [
    "## Training model without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "\n",
    "model = SimpleModel(num_classes=2, conv1_kernel_size=5,dropout=0.1)  # Adjust num_classes as per your requirement\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.9612\n",
      "Epoch [2/5], Loss: 0.7425\n",
      "Epoch [3/5], Loss: 0.7197\n",
      "Epoch [4/5], Loss: 0.7064\n",
      "Epoch [5/5], Loss: 0.6954\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)  \n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b00b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5150\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "def evaluate_model(model, val_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "evaluate_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0329ceb6",
   "metadata": {},
   "source": [
    "## Model training and evaluation with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e598d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.4032\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m0.2122\u001b[0m  14.1114\n",
      "      2        \u001b[36m0.1976\u001b[0m       0.9252        \u001b[35m0.2039\u001b[0m  14.3127\n",
      "      3        0.2001       \u001b[32m0.9439\u001b[0m        \u001b[35m0.1539\u001b[0m  15.2035\n",
      "      4        \u001b[36m0.1490\u001b[0m       \u001b[32m0.9626\u001b[0m        \u001b[35m0.1454\u001b[0m  15.9099\n",
      "      5        \u001b[36m0.1455\u001b[0m       0.9626        \u001b[35m0.1145\u001b[0m  16.1765\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.9637\u001b[0m       \u001b[32m0.9346\u001b[0m        \u001b[35m0.1862\u001b[0m  16.4282\n",
      "      2        \u001b[36m0.2570\u001b[0m       \u001b[32m0.9813\u001b[0m        \u001b[35m0.1127\u001b[0m  16.9342\n",
      "      3        \u001b[36m0.2168\u001b[0m       0.9813        \u001b[35m0.1081\u001b[0m  15.4302\n",
      "      4        \u001b[36m0.1872\u001b[0m       \u001b[32m0.9907\u001b[0m        \u001b[35m0.0771\u001b[0m  16.3055\n",
      "      5        \u001b[36m0.1598\u001b[0m       0.9907        \u001b[35m0.0679\u001b[0m  16.5202\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.5127\u001b[0m       \u001b[32m0.9813\u001b[0m        \u001b[35m0.1142\u001b[0m  15.9362\n",
      "      2        \u001b[36m0.2092\u001b[0m       \u001b[32m1.0000\u001b[0m        \u001b[35m0.0806\u001b[0m  16.5169\n",
      "      3        \u001b[36m0.1798\u001b[0m       0.9907        \u001b[35m0.0681\u001b[0m  17.3565\n",
      "      4        \u001b[36m0.1590\u001b[0m       1.0000        \u001b[35m0.0531\u001b[0m  16.9282\n",
      "      5        \u001b[36m0.1406\u001b[0m       1.0000        \u001b[35m0.0425\u001b[0m  15.5819\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.7893\u001b[0m       \u001b[32m0.8411\u001b[0m        \u001b[35m0.3474\u001b[0m  15.8773\n",
      "      2        \u001b[36m0.2580\u001b[0m       \u001b[32m0.8972\u001b[0m        \u001b[35m0.2368\u001b[0m  15.2100\n",
      "      3        \u001b[36m0.2299\u001b[0m       \u001b[32m0.9346\u001b[0m        \u001b[35m0.1916\u001b[0m  15.6319\n",
      "      4        \u001b[36m0.1807\u001b[0m       \u001b[32m0.9533\u001b[0m        \u001b[35m0.1569\u001b[0m  16.9898\n",
      "      5        \u001b[36m0.1462\u001b[0m       \u001b[32m0.9626\u001b[0m        \u001b[35m0.1252\u001b[0m  14.7222\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.9474\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m0.3063\u001b[0m  14.7933\n",
      "      2        \u001b[36m0.2679\u001b[0m       \u001b[32m0.9533\u001b[0m        \u001b[35m0.1557\u001b[0m  16.6879\n",
      "      3        \u001b[36m0.1581\u001b[0m       0.9533        \u001b[35m0.1117\u001b[0m  16.2831\n",
      "      4        \u001b[36m0.0973\u001b[0m       \u001b[32m0.9720\u001b[0m        \u001b[35m0.0791\u001b[0m  15.0948\n",
      "      5        \u001b[36m0.0485\u001b[0m       \u001b[32m0.9907\u001b[0m        \u001b[35m0.0495\u001b[0m  17.8979\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.6004\u001b[0m       \u001b[32m0.9907\u001b[0m        \u001b[35m0.0910\u001b[0m  12.5388\n",
      "      2        \u001b[36m0.1893\u001b[0m       0.9626        0.1102  17.2679\n",
      "      3        \u001b[36m0.1583\u001b[0m       0.9907        \u001b[35m0.0567\u001b[0m  15.6409\n",
      "      4        \u001b[36m0.1225\u001b[0m       \u001b[32m1.0000\u001b[0m        \u001b[35m0.0413\u001b[0m  17.1904\n",
      "      5        \u001b[36m0.0945\u001b[0m       1.0000        \u001b[35m0.0302\u001b[0m  16.4163\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.4858\u001b[0m       \u001b[32m0.9533\u001b[0m        \u001b[35m0.2271\u001b[0m  17.3949\n",
      "      2        \u001b[36m0.2025\u001b[0m       \u001b[32m0.9626\u001b[0m        \u001b[35m0.1950\u001b[0m  16.9277\n",
      "      3        \u001b[36m0.1275\u001b[0m       0.9626        \u001b[35m0.1535\u001b[0m  15.4650\n",
      "      4        \u001b[36m0.0910\u001b[0m       \u001b[32m0.9720\u001b[0m        \u001b[35m0.1306\u001b[0m  15.1874\n",
      "      5        \u001b[36m0.0683\u001b[0m       0.9626        0.1379  17.4338\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.4501\u001b[0m       \u001b[32m0.9907\u001b[0m        \u001b[35m0.0777\u001b[0m  16.1849\n",
      "      2        \u001b[36m0.2235\u001b[0m       0.9813        0.0933  16.3799\n",
      "      3        \u001b[36m0.1969\u001b[0m       0.9907        0.0778  16.3330\n",
      "      4        \u001b[36m0.1719\u001b[0m       0.9813        \u001b[35m0.0646\u001b[0m  17.0254\n",
      "      5        \u001b[36m0.1620\u001b[0m       \u001b[32m1.0000\u001b[0m        \u001b[35m0.0537\u001b[0m  19.0568\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.3174\u001b[0m       \u001b[32m1.0000\u001b[0m        \u001b[35m0.0518\u001b[0m  16.5651\n",
      "      2        \u001b[36m0.1648\u001b[0m       1.0000        \u001b[35m0.0486\u001b[0m  15.8956\n",
      "      3        \u001b[36m0.1383\u001b[0m       1.0000        \u001b[35m0.0385\u001b[0m  17.4432\n",
      "      4        \u001b[36m0.1215\u001b[0m       1.0000        \u001b[35m0.0286\u001b[0m  16.2757\n",
      "      5        \u001b[36m0.1085\u001b[0m       1.0000        \u001b[35m0.0247\u001b[0m  16.0798\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.2894\u001b[0m       \u001b[32m0.9688\u001b[0m        \u001b[35m0.1035\u001b[0m  23.4138\n",
      "      2        \u001b[36m0.1883\u001b[0m       \u001b[32m0.9750\u001b[0m        \u001b[35m0.0876\u001b[0m  24.4911\n",
      "      3        \u001b[36m0.1613\u001b[0m       0.9750        \u001b[35m0.0724\u001b[0m  23.9839\n",
      "      4        \u001b[36m0.1503\u001b[0m       \u001b[32m1.0000\u001b[0m        \u001b[35m0.0393\u001b[0m  22.4021\n",
      "      5        \u001b[36m0.1283\u001b[0m       1.0000        \u001b[35m0.0328\u001b[0m  23.4009\n",
      "Best parameters found:  {'module__conv1_kernel_size': 4, 'module__dropout': 0.4}\n",
      "Best accuracy found:  0.9737311443402513\n"
     ]
    }
   ],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the Skorch classifier with the given PyTorch model\n",
    "net = NeuralNetClassifier(\n",
    "    module=SimpleModel,\n",
    "    module__num_classes=num_classes,  # Pass additional parameters to the model\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=optim.Adam,\n",
    "    optimizer__lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=5,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    ")\n",
    "\n",
    "# Extract data and labels from the DataLoader\n",
    "X_train = []\n",
    "y_train = []\n",
    "for images, labels in train_loader:\n",
    "    X_train.append(images.numpy())  # Assuming images are numpy arrays\n",
    "    y_train.append(labels.numpy())  # Assuming labels are numpy arrays\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "params = {\n",
    "    'module__dropout': [0.1, 0.4, 0.6],\n",
    "    'module__conv1_kernel_size': [2,3,4],\n",
    "\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gs = GridSearchCV(net, params, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Train the model with hyperparameter tuning\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", gs.best_params_)\n",
    "print(\"Best accuracy found: \", gs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada6c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy after Hyper parameter tuning: 0.9732142857142857\n"
     ]
    }
   ],
   "source": [
    "best_net = gs.best_estimator_\n",
    "\n",
    "scores=[]\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        score= best_net.score(images,labels)\n",
    "        scores.append(score)\n",
    "print(f\"Validation Accuracy after Hyper parameter tuning: {np.mean(scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
