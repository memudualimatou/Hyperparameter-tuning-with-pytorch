{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09bf57ed",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56206916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2 \n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from zipfile import ZipFile\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from keras.utils import to_categorical\n",
    "from tqdm.notebook import tqdm \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36012652",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ab35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzip Data Completed\n"
     ]
    }
   ],
   "source": [
    "num_samples = 500\n",
    "folder_path = r\"animal classification\"\n",
    "data_path = os.path.join(folder_path, 'Data')\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "def unzip_data():\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file) \n",
    "            if path.endswith(\".zip\"):\n",
    "                with ZipFile(path, 'r') as zf:\n",
    "                    zf.extractall(path=data_path)\n",
    "    print(\"Unzip Data Completed\")\n",
    "\n",
    "unzip_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56947dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_elephants\n",
      "train_zebras\n",
      "__MACOSX\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASG0014jyv_0.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_elephants\\ASG...</td>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASG001dwaq_2.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_zebras\\ASG001...</td>\n",
       "      <td>zebras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASG001e0oc_0.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_zebras\\ASG001...</td>\n",
       "      <td>zebras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASG001e0lr_1.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_zebras\\ASG001...</td>\n",
       "      <td>zebras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASG0014jhi_0.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_elephants\\ASG...</td>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>ASG0014ip9_2.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_elephants\\ASG...</td>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ASG0014k1j_1.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_elephants\\ASG...</td>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>ASG0014jky_0.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_elephants\\ASG...</td>\n",
       "      <td>elephants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>ASG001e0op_0.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_zebras\\ASG001...</td>\n",
       "      <td>zebras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ASG001dwdg_2.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_zebras\\ASG001...</td>\n",
       "      <td>zebras</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image                                           filepath   \n",
       "0    ASG0014jyv_0.jpeg  animal classification\\Data\\train_elephants\\ASG...  \\\n",
       "1    ASG001dwaq_2.jpeg  animal classification\\Data\\train_zebras\\ASG001...   \n",
       "2    ASG001e0oc_0.jpeg  animal classification\\Data\\train_zebras\\ASG001...   \n",
       "3    ASG001e0lr_1.jpeg  animal classification\\Data\\train_zebras\\ASG001...   \n",
       "4    ASG0014jhi_0.jpeg  animal classification\\Data\\train_elephants\\ASG...   \n",
       "..                 ...                                                ...   \n",
       "995  ASG0014ip9_2.jpeg  animal classification\\Data\\train_elephants\\ASG...   \n",
       "996  ASG0014k1j_1.jpeg  animal classification\\Data\\train_elephants\\ASG...   \n",
       "997  ASG0014jky_0.jpeg  animal classification\\Data\\train_elephants\\ASG...   \n",
       "998  ASG001e0op_0.jpeg  animal classification\\Data\\train_zebras\\ASG001...   \n",
       "999  ASG001dwdg_2.jpeg  animal classification\\Data\\train_zebras\\ASG001...   \n",
       "\n",
       "        target  \n",
       "0    elephants  \n",
       "1       zebras  \n",
       "2       zebras  \n",
       "3       zebras  \n",
       "4    elephants  \n",
       "..         ...  \n",
       "995  elephants  \n",
       "996  elephants  \n",
       "997  elephants  \n",
       "998     zebras  \n",
       "999     zebras  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building our dataset\n",
    "def build_data():\n",
    "    data = []\n",
    "    for folder in os.listdir(data_path):\n",
    "        print(folder)\n",
    "        if folder.startswith(\"train_\"):\n",
    "            target = folder.split(\"_\")[-1]\n",
    "            folder_path = os.path.join(data_path, folder)\n",
    "            files_class = []\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(\".jpeg\") and len(files_class) < num_samples:\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    files_class.append(file_path)\n",
    "                    data.append({'image': file_name, 'filepath': file_path, 'target': target})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "data = build_data()\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93ed59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASG0014jyv_0.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_elephants\\ASG...</td>\n",
       "      <td>elephants</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASG001dwaq_2.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_zebras\\ASG001...</td>\n",
       "      <td>zebras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASG001e0oc_0.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_zebras\\ASG001...</td>\n",
       "      <td>zebras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASG001e0lr_1.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_zebras\\ASG001...</td>\n",
       "      <td>zebras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASG0014jhi_0.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_elephants\\ASG...</td>\n",
       "      <td>elephants</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>ASG0014ip9_2.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_elephants\\ASG...</td>\n",
       "      <td>elephants</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ASG0014k1j_1.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_elephants\\ASG...</td>\n",
       "      <td>elephants</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>ASG0014jky_0.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_elephants\\ASG...</td>\n",
       "      <td>elephants</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>ASG001e0op_0.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_zebras\\ASG001...</td>\n",
       "      <td>zebras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ASG001dwdg_2.jpeg</td>\n",
       "      <td>animal classification\\Data\\train_zebras\\ASG001...</td>\n",
       "      <td>zebras</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image                                           filepath   \n",
       "0    ASG0014jyv_0.jpeg  animal classification\\Data\\train_elephants\\ASG...  \\\n",
       "1    ASG001dwaq_2.jpeg  animal classification\\Data\\train_zebras\\ASG001...   \n",
       "2    ASG001e0oc_0.jpeg  animal classification\\Data\\train_zebras\\ASG001...   \n",
       "3    ASG001e0lr_1.jpeg  animal classification\\Data\\train_zebras\\ASG001...   \n",
       "4    ASG0014jhi_0.jpeg  animal classification\\Data\\train_elephants\\ASG...   \n",
       "..                 ...                                                ...   \n",
       "995  ASG0014ip9_2.jpeg  animal classification\\Data\\train_elephants\\ASG...   \n",
       "996  ASG0014k1j_1.jpeg  animal classification\\Data\\train_elephants\\ASG...   \n",
       "997  ASG0014jky_0.jpeg  animal classification\\Data\\train_elephants\\ASG...   \n",
       "998  ASG001e0op_0.jpeg  animal classification\\Data\\train_zebras\\ASG001...   \n",
       "999  ASG001dwdg_2.jpeg  animal classification\\Data\\train_zebras\\ASG001...   \n",
       "\n",
       "        target  class  \n",
       "0    elephants      0  \n",
       "1       zebras      1  \n",
       "2       zebras      1  \n",
       "3       zebras      1  \n",
       "4    elephants      0  \n",
       "..         ...    ...  \n",
       "995  elephants      0  \n",
       "996  elephants      0  \n",
       "997  elephants      0  \n",
       "998     zebras      1  \n",
       "999     zebras      1  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert string labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['class'] = label_encoder.fit_transform(data['target'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225994e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'animal classification\\\\Data\\\\train_elephants\\\\ASG0014jyv_0.jpeg'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['filepath'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a5f4c",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb7dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 800\n",
      "Validation dataset size: 200\n"
     ]
    }
   ],
   "source": [
    "class_samples = data.groupby('target').head(num_samples)\n",
    "train_size = int(0.8 * len(class_samples))\n",
    "train_dataset = class_samples[:train_size]\n",
    "val_dataset = class_samples[train_size:]\n",
    "\n",
    "print(\"Training dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d111f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images and CSV files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# saving train and validation images into a folder\n",
    "\n",
    "train_images_folder = os.path.join(data_path, 'train_images')\n",
    "val_images_folder = os.path.join(data_path, 'val_images')\n",
    "os.makedirs(train_images_folder, exist_ok=True)\n",
    "os.makedirs(val_images_folder, exist_ok=True)\n",
    "\n",
    "# Save training  and validation images\n",
    "def save_images(dataset, target_folder):\n",
    "    for index, row in dataset.iterrows():\n",
    "        image_path = row['filepath']\n",
    "        target_class = row['target']\n",
    "        class_folder = os.path.join(target_folder, target_class)\n",
    "        os.makedirs(class_folder, exist_ok=True)\n",
    "        shutil.copy(image_path, class_folder)\n",
    "\n",
    "\n",
    "save_images(train_dataset, train_images_folder)\n",
    "save_images(val_dataset, val_images_folder)\n",
    "\n",
    "# Save files\n",
    "train_csv_path=os.path.join(data_path,'train_dataset.csv')\n",
    "val_csv_path=os.path.join(data_path,'val_dataset.csv')\n",
    "train_dataset.to_csv(train_csv_path, index=False)\n",
    "val_dataset.to_csv(val_csv_path, index=False)\n",
    "\n",
    "print(\"Images and CSV files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f22edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_frame.iloc[idx, 1])\n",
    "        image = Image.open(img_name)\n",
    "        label = self.data_frame.iloc[idx, 3]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7fa63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations and dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(csv_file=train_csv_path, root_dir=train_images_folder, transform=transform)\n",
    "val_dataset = CustomDataset(csv_file=val_csv_path, root_dir=val_images_folder, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c79c186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes=len(np.unique(data['target']))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0307da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, num_classes, conv1_kernel_size=5,dropout=0.3):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=conv1_kernel_size, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=conv1_kernel_size, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 128)  \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  \n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x)) \n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.view(-1, 16 * 56 * 56)\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc1(x)) \n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55faac39",
   "metadata": {},
   "source": [
    "## Training model without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "\n",
    "model = SimpleModel(num_classes=2, conv1_kernel_size=5,dropout=0.1)  \n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9170\n",
      "Epoch [2/10], Loss: 0.7184\n",
      "Epoch [3/10], Loss: 0.7051\n",
      "Epoch [4/10], Loss: 0.6943\n",
      "Epoch [5/10], Loss: 0.7085\n",
      "Epoch [6/10], Loss: 0.7029\n",
      "Epoch [7/10], Loss: 0.7082\n",
      "Epoch [8/10], Loss: 0.7127\n",
      "Epoch [9/10], Loss: 0.7064\n",
      "Epoch [10/10], Loss: 0.7207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)  \n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b00b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5200\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "def evaluate_model(model, val_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "evaluate_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0329ceb6",
   "metadata": {},
   "source": [
    "## Model training and evaluation with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e598d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.3596\u001b[0m       \u001b[32m0.8972\u001b[0m        \u001b[35m0.3597\u001b[0m  4.1339\n",
      "      2        \u001b[36m0.2123\u001b[0m       \u001b[32m0.9159\u001b[0m        \u001b[35m0.2437\u001b[0m  4.2289\n",
      "      3        \u001b[36m0.1658\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m0.2367\u001b[0m  4.1556\n",
      "      4        \u001b[36m0.1483\u001b[0m       \u001b[32m0.9346\u001b[0m        \u001b[35m0.1937\u001b[0m  4.3973\n",
      "      5        \u001b[36m0.1306\u001b[0m       \u001b[32m0.9439\u001b[0m        \u001b[35m0.1673\u001b[0m  4.1704\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3780\u001b[0m       \u001b[32m0.4953\u001b[0m        \u001b[35m1.0678\u001b[0m  4.2717\n",
      "      2        \u001b[36m0.8895\u001b[0m       0.4953        \u001b[35m0.7430\u001b[0m  4.0638\n",
      "      3        \u001b[36m0.7013\u001b[0m       \u001b[32m0.5047\u001b[0m        \u001b[35m0.6946\u001b[0m  4.0804\n",
      "      4        \u001b[36m0.6979\u001b[0m       0.5047        0.7013  4.1796\n",
      "      5        0.6997       0.5047        0.6952  4.1656\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7239\u001b[0m       \u001b[32m0.4953\u001b[0m        \u001b[35m1.3081\u001b[0m  4.0438\n",
      "      2        \u001b[36m1.0123\u001b[0m       \u001b[32m0.6449\u001b[0m        \u001b[35m0.6486\u001b[0m  4.1839\n",
      "      3        \u001b[36m0.5084\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m0.3077\u001b[0m  4.0591\n",
      "      4        \u001b[36m0.2785\u001b[0m       \u001b[32m0.9439\u001b[0m        \u001b[35m0.2172\u001b[0m  4.0432\n",
      "      5        \u001b[36m0.1927\u001b[0m       \u001b[32m0.9907\u001b[0m        \u001b[35m0.1491\u001b[0m  4.2042\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4285\u001b[0m       \u001b[32m0.8879\u001b[0m        \u001b[35m0.3562\u001b[0m  4.0455\n",
      "      2        \u001b[36m0.2206\u001b[0m       \u001b[32m0.9159\u001b[0m        \u001b[35m0.2524\u001b[0m  4.2252\n",
      "      3        \u001b[36m0.1724\u001b[0m       0.9159        \u001b[35m0.2124\u001b[0m  4.2977\n",
      "      4        \u001b[36m0.1475\u001b[0m       \u001b[32m0.9439\u001b[0m        \u001b[35m0.1808\u001b[0m  4.2722\n",
      "      5        \u001b[36m0.1250\u001b[0m       0.9439        \u001b[35m0.1639\u001b[0m  4.1156\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.1388\u001b[0m       \u001b[32m0.8505\u001b[0m        \u001b[35m0.3879\u001b[0m  4.1566\n",
      "      2        \u001b[36m0.2181\u001b[0m       \u001b[32m0.9159\u001b[0m        \u001b[35m0.2988\u001b[0m  4.0880\n",
      "      3        \u001b[36m0.1842\u001b[0m       0.9159        \u001b[35m0.2922\u001b[0m  4.1017\n",
      "      4        \u001b[36m0.1518\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m0.2497\u001b[0m  4.1846\n",
      "      5        \u001b[36m0.1300\u001b[0m       \u001b[32m0.9346\u001b[0m        \u001b[35m0.2341\u001b[0m  4.2035\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7102\u001b[0m       \u001b[32m0.4953\u001b[0m        \u001b[35m1.3088\u001b[0m  4.1341\n",
      "      2        \u001b[36m1.0480\u001b[0m       0.4953        \u001b[35m0.7830\u001b[0m  4.2056\n",
      "      3        \u001b[36m0.6211\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m0.3494\u001b[0m  4.2350\n",
      "      4        \u001b[36m0.3081\u001b[0m       0.9252        \u001b[35m0.2644\u001b[0m  4.2789\n",
      "      5        \u001b[36m0.2279\u001b[0m       0.9252        \u001b[35m0.1986\u001b[0m  4.3332\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.2726\u001b[0m       \u001b[32m0.5047\u001b[0m        \u001b[35m1.0046\u001b[0m  4.1858\n",
      "      2        \u001b[36m0.8499\u001b[0m       0.5047        \u001b[35m0.7164\u001b[0m  4.2731\n",
      "      3        \u001b[36m0.6992\u001b[0m       0.4953        \u001b[35m0.6967\u001b[0m  4.3148\n",
      "      4        \u001b[36m0.6967\u001b[0m       0.4953        \u001b[35m0.6950\u001b[0m  4.1240\n",
      "      5        \u001b[36m0.6932\u001b[0m       0.5047        \u001b[35m0.6930\u001b[0m  4.0850\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0460\u001b[0m       \u001b[32m0.8972\u001b[0m        \u001b[35m0.3464\u001b[0m  3.9452\n",
      "      2        \u001b[36m0.1966\u001b[0m       \u001b[32m0.9159\u001b[0m        \u001b[35m0.2663\u001b[0m  4.1676\n",
      "      3        \u001b[36m0.1640\u001b[0m       0.9159        \u001b[35m0.2517\u001b[0m  4.1011\n",
      "      4        \u001b[36m0.1462\u001b[0m       \u001b[32m0.9252\u001b[0m        \u001b[35m0.2417\u001b[0m  4.3561\n",
      "      5        \u001b[36m0.1332\u001b[0m       0.9252        0.2421  4.2599\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.6948\u001b[0m       \u001b[32m0.4953\u001b[0m        \u001b[35m1.1180\u001b[0m  4.2977\n",
      "      2        \u001b[36m0.6547\u001b[0m       \u001b[32m0.7664\u001b[0m        \u001b[35m0.4502\u001b[0m  4.2277\n",
      "      3        \u001b[36m0.4525\u001b[0m       \u001b[32m0.8879\u001b[0m        \u001b[35m0.3156\u001b[0m  4.1411\n",
      "      4        \u001b[36m0.3375\u001b[0m       \u001b[32m0.9439\u001b[0m        \u001b[35m0.2196\u001b[0m  4.1302\n",
      "      5        \u001b[36m0.2120\u001b[0m       \u001b[32m0.9720\u001b[0m        \u001b[35m0.1527\u001b[0m  4.0807\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5166\u001b[0m       \u001b[32m0.9187\u001b[0m        \u001b[35m0.2245\u001b[0m  6.1836\n",
      "      2        \u001b[36m0.1651\u001b[0m       \u001b[32m0.9437\u001b[0m        \u001b[35m0.1802\u001b[0m  6.2585\n",
      "      3        \u001b[36m0.1131\u001b[0m       \u001b[32m0.9563\u001b[0m        \u001b[35m0.1555\u001b[0m  6.3436\n",
      "      4        \u001b[36m0.0815\u001b[0m       0.9563        \u001b[35m0.1417\u001b[0m  6.3080\n",
      "      5        \u001b[36m0.0647\u001b[0m       0.9563        \u001b[35m0.1003\u001b[0m  6.3660\n",
      "Best parameters found:  {'module__conv1_kernel_size': 4, 'module__dropout': 0.4}\n",
      "Best accuracy found:  0.9512639276092854\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the Skorch classifier with the given PyTorch model\n",
    "net = NeuralNetClassifier(\n",
    "    module=SimpleModel,\n",
    "    module__num_classes=num_classes,  \n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=optim.Adam,\n",
    "    optimizer__lr=0.001,\n",
    "    batch_size=32,\n",
    "    max_epochs=5,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    ")\n",
    "\n",
    "# Extract data and labels \n",
    "X_train = []\n",
    "y_train = []\n",
    "for images, labels in train_loader:\n",
    "    X_train.append(images.numpy())  \n",
    "    y_train.append(labels.numpy())  \n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# Defining the hyperparameters \n",
    "params = {\n",
    "    'module__dropout': [0.1, 0.4, 0.6],\n",
    "    'module__conv1_kernel_size': [2,3,4],\n",
    "\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gs = GridSearchCV(net, params, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters found: \", gs.best_params_)\n",
    "print(\"Best accuracy found: \", gs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada6c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy after Hyper parameter tuning: 0.9821428571428571\n"
     ]
    }
   ],
   "source": [
    "best_net = gs.best_estimator_\n",
    "\n",
    "scores=[]\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        score= best_net.score(images,labels)\n",
    "        scores.append(score)\n",
    "print(f\"Validation Accuracy after Hyper parameter tuning: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c565670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
